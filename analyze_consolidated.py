#!/usr/bin/env python3
"""
Script d'analyse du fichier JSON consolidÃ©.
Fournit des statistiques dÃ©taillÃ©es sur les recherches et offres d'emploi.
"""

import json
import os
from datetime import datetime
from collections import Counter
import sys

def analyze_consolidated_file():
    """Analyse le fichier JSON consolidÃ© et affiche les statistiques."""
    
    consolidated_file = "Exports/linkedin_job_searches_consolidated.json"
    
    if not os.path.exists(consolidated_file):
        print("âŒ Fichier consolidÃ© non trouvÃ©.")
        print(f"ğŸ“ Recherche dans : {os.path.abspath(consolidated_file)}")
        print("ğŸ’¡ Effectuez d'abord quelques recherches LinkedIn !")
        return False
    
    try:
        with open(consolidated_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError:
        print("âŒ Erreur : Fichier JSON corrompu")
        return False
    
    # Affichage des informations principales
    print("ğŸ“Š ANALYSE DU FICHIER CONSOLIDÃ‰ LinkedIn Job Search")
    print("=" * 60)
    
    metadata = data.get('metadata', {})
    search_history = data.get('search_history', [])
    jobs = data.get('jobs', [])
    
    # MÃ©tadonnÃ©es gÃ©nÃ©rales
    print(f"ğŸ“… CrÃ©Ã© le : {metadata.get('creation_date', 'N/A')}")
    print(f"ğŸ”„ DerniÃ¨re mise Ã  jour : {metadata.get('last_updated', 'N/A')}")
    print(f"ğŸ“ˆ Version d'export : {metadata.get('export_version', 'N/A')}")
    print(f"ğŸ” Total recherches : {metadata.get('total_searches', 0)}")
    print(f"ğŸ’¼ Total offres uniques : {metadata.get('total_jobs', 0)}")
    
    if not search_history:
        print("\nâš ï¸ Aucun historique de recherche trouvÃ©")
        return True
    
    # Analyse des recherches
    print(f"\nğŸ“‹ HISTORIQUE DES RECHERCHES ({len(search_history)})")
    print("-" * 40)
    
    total_jobs_found = 0
    keywords_counter = Counter()
    locations_counter = Counter()
    
    for i, search in enumerate(search_history, 1):
        keywords = search.get('keywords', 'N/A')
        location = search.get('location', 'N/A')
        jobs_found = search.get('jobs_found', 0)
        timestamp = search.get('search_timestamp', 'N/A')
        
        print(f"{i:2}. {keywords} @ {location}")
        print(f"    ğŸ“Š {jobs_found} offres trouvÃ©es - {timestamp[:19]}")
        
        # Filtres appliquÃ©s
        filters = search.get('search_filters', {})
        filter_info = []
        
        if filters.get('job_types', {}).get('description'):
            filter_info.append(f"Type: {', '.join(filters['job_types']['description'])}")
        if filters.get('remote_work', {}).get('description'):
            filter_info.append(f"Mode: {', '.join(filters['remote_work']['description'])}")
        if filters.get('experience_levels', {}).get('description'):
            filter_info.append(f"Exp: {', '.join(filters['experience_levels']['description'])}")
        
        if filter_info:
            print(f"    ğŸ”§ Filtres: {' | '.join(filter_info)}")
        
        print()
        
        total_jobs_found += jobs_found
        keywords_counter[keywords] += 1
        locations_counter[location] += 1
    
    # Statistiques des offres
    if jobs:
        print(f"ğŸ’¼ ANALYSE DES OFFRES D'EMPLOI ({len(jobs)})")
        print("-" * 40)
        
        # Analyse par entreprise
        companies = [job.get('company', 'N/A') for job in jobs]
        company_counter = Counter(companies)
        
        print("ğŸ¢ Top 5 entreprises :")
        for company, count in company_counter.most_common(5):
            print(f"   {company}: {count} offres")
        
        # Analyse par lieu
        job_locations = [job.get('location', 'N/A') for job in jobs]
        job_location_counter = Counter(job_locations)
        
        print("\nğŸ“ Top 5 localisations :")
        for location, count in job_location_counter.most_common(5):
            print(f"   {location}: {count} offres")
        
        # Types de travail
        workplace_types = [job.get('workplace_type', 'N/A') for job in jobs if job.get('workplace_type')]
        if workplace_types:
            workplace_counter = Counter(workplace_types)
            print("\nğŸ  Types de tÃ©lÃ©travail :")
            for wtype, count in workplace_counter.most_common():
                print(f"   {wtype}: {count} offres")
        
        # Job nature
        job_natures = [job.get('job_nature', 'N/A') for job in jobs if job.get('job_nature')]
        if job_natures:
            nature_counter = Counter(job_natures)
            print("\nğŸ’¼ Types de contrat :")
            for nature, count in nature_counter.most_common():
                print(f"   {nature}: {count} offres")
    
    # Statistiques des recherches
    print(f"\nğŸ” STATISTIQUES DES RECHERCHES")
    print("-" * 40)
    
    print("ğŸ¯ Mots-clÃ©s les plus recherchÃ©s :")
    for keyword, count in keywords_counter.most_common(5):
        print(f"   {keyword}: {count} fois")
    
    print(f"\nğŸ“ Localisations les plus recherchÃ©es :")
    for location, count in locations_counter.most_common(5):
        print(f"   {location}: {count} fois")
    
    # EfficacitÃ© des recherches
    if total_jobs_found > 0:
        avg_jobs_per_search = total_jobs_found / len(search_history)
        unique_rate = (len(jobs) / total_jobs_found) * 100 if total_jobs_found > 0 else 0
        
        print(f"\nğŸ“ˆ MÃ‰TRIQUES D'EFFICACITÃ‰")
        print("-" * 40)
        print(f"ğŸ“Š Moyenne offres/recherche : {avg_jobs_per_search:.1f}")
        print(f"ğŸ¯ Taux d'unicitÃ© : {unique_rate:.1f}% ({len(jobs)}/{total_jobs_found})")
        print(f"ğŸ”„ Doublons Ã©vitÃ©s : {total_jobs_found - len(jobs)}")
    
    print(f"\nğŸ“ Fichier analysÃ© : {os.path.abspath(consolidated_file)}")
    
    return True

if __name__ == "__main__":
    if not analyze_consolidated_file():
        sys.exit(1)